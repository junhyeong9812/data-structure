# 23. ë¬¸ì„œ ì¸ë±ì„œ (Document Indexer)

## ğŸ“‹ ë¬¸ì œ ì •ì˜

**ì „ë¬¸ ê²€ìƒ‰(Full-Text Search)**ì„ ìœ„í•œ ì—­ì¸ë±ìŠ¤(Inverted Index) ê¸°ë°˜ 
ë¬¸ì„œ ì¸ë±ì„œë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

ë¬¸ì„œ ì¸ë±ì„œëŠ” ê²€ìƒ‰ ì—”ì§„ì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œë¡œ, ëŒ€ëŸ‰ì˜ ë¬¸ì„œì—ì„œ 
í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì„ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

- ì—­ì¸ë±ìŠ¤(Inverted Index) êµ¬ì¡°
- í† í°í™”(Tokenization)
- TF-IDF ìŠ¤ì½”ì–´ë§
- ë¶ˆìš©ì–´(Stop Words) ì²˜ë¦¬
- ê²€ìƒ‰ ë­í‚¹ ì•Œê³ ë¦¬ì¦˜

---

## ğŸ“ ìš”êµ¬ì‚¬í•­

### í•µì‹¬ ê°œë…

| ê°œë… | ì„¤ëª… |
|------|------|
| **Inverted Index** | ë‹¨ì–´ â†’ ë¬¸ì„œ ID ëª©ë¡ ë§¤í•‘ |
| **Tokenization** | ë¬¸ì„œë¥¼ ë‹¨ì–´ë¡œ ë¶„ë¦¬ |
| **TF (Term Frequency)** | ë‹¨ì–´ì˜ ë¬¸ì„œ ë‚´ ë¹ˆë„ |
| **IDF (Inverse Document Frequency)** | ë‹¨ì–´ì˜ í¬ì†Œì„± |
| **TF-IDF** | TF Ã— IDF, ê²€ìƒ‰ ê´€ë ¨ì„± ì ìˆ˜ |

### ê¸°ë³¸ ì—°ì‚°

| ë©”ì„œë“œ | ì„¤ëª… |
|--------|------|
| `addDocument(id, content)` | ë¬¸ì„œ ì¸ë±ì‹± |
| `removeDocument(id)` | ë¬¸ì„œ ì œê±° |
| `search(query)` | ê²€ìƒ‰ (ê´€ë ¨ì„± ìˆœ) |
| `searchWithScore(query)` | ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰ |

### ê²€ìƒ‰ ì˜µì…˜

| ì˜µì…˜ | ì„¤ëª… |
|------|------|
| `AND` | ëª¨ë“  í‚¤ì›Œë“œ í¬í•¨ |
| `OR` | í•˜ë‚˜ ì´ìƒ í‚¤ì›Œë“œ í¬í•¨ |
| `phrase` | êµ¬ë¬¸ ê²€ìƒ‰ (ì—°ì†ëœ ë‹¨ì–´) |

---

## ğŸ“Š ì…ì¶œë ¥ ì˜ˆì‹œ

### ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ìš©
```java
DocumentIndexer indexer = new DocumentIndexer();

// ë¬¸ì„œ ì¶”ê°€
indexer.addDocument("doc1", "The quick brown fox jumps over the lazy dog");
indexer.addDocument("doc2", "A quick brown dog runs in the park");
indexer.addDocument("doc3", "The lazy cat sleeps all day");

// ê²€ìƒ‰
List<String> results = indexer.search("quick brown");
// ["doc1", "doc2"] - ë‘ ë‹¨ì–´ê°€ ëª¨ë‘ ìˆëŠ” ë¬¸ì„œ

List<String> results2 = indexer.search("lazy");
// ["doc1", "doc3"] - lazyê°€ ìˆëŠ” ë¬¸ì„œ
```

### ì˜ˆì œ 2: TF-IDF ìŠ¤ì½”ì–´ë§
```java
// ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰
List<SearchResult> results = indexer.searchWithScore("quick fox");

// doc1: quick(1ë²ˆ) + fox(1ë²ˆ) â†’ ë†’ì€ ì ìˆ˜
// doc2: quick(1ë²ˆ) + fox(0ë²ˆ) â†’ ë‚®ì€ ì ìˆ˜

for (SearchResult r : results) {
    System.out.println(r.docId() + ": " + r.score());
}
// doc1: 0.85
// doc2: 0.42
```

### ì˜ˆì œ 3: ì—­ì¸ë±ìŠ¤ êµ¬ì¡°
```
ë¬¸ì„œë“¤:
  doc1: "cat dog cat"
  doc2: "dog bird"
  doc3: "cat bird cat cat"

ì—­ì¸ë±ìŠ¤:
  "cat"  â†’ [(doc1, 2), (doc3, 3)]
  "dog"  â†’ [(doc1, 1), (doc2, 1)]
  "bird" â†’ [(doc2, 1), (doc3, 1)]

ê²€ìƒ‰ "cat dog":
  cat í¬í•¨: doc1, doc3
  dog í¬í•¨: doc1, doc2
  AND ê²°ê³¼: doc1 (ë‘˜ ë‹¤ í¬í•¨)
```

### ì˜ˆì œ 4: TF-IDF ê³„ì‚°
```
TF(t, d) = ë‹¨ì–´ tê°€ ë¬¸ì„œ dì— ë‚˜íƒ€ë‚œ íšŸìˆ˜ / ë¬¸ì„œ dì˜ ì´ ë‹¨ì–´ ìˆ˜

IDF(t) = log(ì „ì²´ ë¬¸ì„œ ìˆ˜ / ë‹¨ì–´ të¥¼ í¬í•¨í•˜ëŠ” ë¬¸ì„œ ìˆ˜)

TF-IDF(t, d) = TF(t, d) Ã— IDF(t)

ì˜ˆ: 3ê°œ ë¬¸ì„œ, "cat"ì´ 2ê°œ ë¬¸ì„œì— ë“±ì¥
  IDF("cat") = log(3/2) â‰ˆ 0.176
  
  doc1ì—ì„œ "cat" 2ë²ˆ, ì´ 3ë‹¨ì–´
  TF("cat", doc1) = 2/3 â‰ˆ 0.667
  
  TF-IDF("cat", doc1) = 0.667 Ã— 0.176 â‰ˆ 0.117
```

---

## ğŸ” í•µì‹¬ ê°œë…

### ì—­ì¸ë±ìŠ¤ êµ¬ì¡°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Inverted Index                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  Term      â”‚  Posting List              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  "apple"   â”‚  [(doc1,3), (doc5,1)]     â”‚
â”‚  "banana"  â”‚  [(doc2,2), (doc3,4)]     â”‚
â”‚  "cat"     â”‚  [(doc1,1), (doc2,1)]     â”‚
â”‚  "dog"     â”‚  [(doc4,2)]               â”‚
â”‚  ...       â”‚  ...                       â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Posting List êµ¬ì¡°:
  (ë¬¸ì„œID, í•´ë‹¹ ë¬¸ì„œì—ì„œì˜ ì¶œí˜„ íšŸìˆ˜)
```

### í† í°í™” íŒŒì´í”„ë¼ì¸
```
ì›ë³¸: "The Quick BROWN fox's"
      â†“
ì†Œë¬¸ì ë³€í™˜: "the quick brown fox's"
      â†“
êµ¬ë‘ì  ì œê±°: "the quick brown foxs"
      â†“
ë¶ˆìš©ì–´ ì œê±°: "quick brown foxs"
      â†“
ìŠ¤í…Œë°(ì„ íƒ): "quick brown fox"
      â†“
í† í°: ["quick", "brown", "fox"]
```

---

## ğŸ’¡ íŒíŠ¸

### ê¸°ë³¸ êµ¬ì¡°
```java
public class DocumentIndexer {
    // ì—­ì¸ë±ìŠ¤: ë‹¨ì–´ â†’ (ë¬¸ì„œID â†’ ì¶œí˜„íšŸìˆ˜)
    private final Map<String, Map<String, Integer>> invertedIndex;
    
    // ë¬¸ì„œ ì €ì¥ì†Œ: ë¬¸ì„œID â†’ ì›ë³¸ ë‚´ìš©
    private final Map<String, String> documents;
    
    // ë¬¸ì„œë³„ ë‹¨ì–´ ìˆ˜
    private final Map<String, Integer> documentLengths;
    
    // ë¶ˆìš©ì–´ ì§‘í•©
    private final Set<String> stopWords;
    
    public DocumentIndexer() {
        this.invertedIndex = new HashMap<>();
        this.documents = new HashMap<>();
        this.documentLengths = new HashMap<>();
        this.stopWords = Set.of("the", "a", "an", "is", "are", "in", "on", "at");
    }
}
```

### í† í°í™”
```java
private List<String> tokenize(String content) {
    return Arrays.stream(content.toLowerCase()
            .replaceAll("[^a-z0-9\\s]", "")
            .split("\\s+"))
        .filter(token -> !token.isEmpty())
        .filter(token -> !stopWords.contains(token))
        .toList();
}
```

### ë¬¸ì„œ ì¸ë±ì‹±
```java
public void addDocument(String docId, String content) {
    documents.put(docId, content);
    
    List<String> tokens = tokenize(content);
    documentLengths.put(docId, tokens.size());
    
    // ë‹¨ì–´ë³„ ë¹ˆë„ ê³„ì‚°
    Map<String, Integer> termFreq = new HashMap<>();
    for (String token : tokens) {
        termFreq.merge(token, 1, Integer::sum);
    }
    
    // ì—­ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    for (Map.Entry<String, Integer> entry : termFreq.entrySet()) {
        invertedIndex.computeIfAbsent(entry.getKey(), k -> new HashMap<>())
            .put(docId, entry.getValue());
    }
}
```

### TF-IDF ê³„ì‚°
```java
private double calculateTfIdf(String term, String docId) {
    Map<String, Integer> postings = invertedIndex.get(term);
    if (postings == null || !postings.containsKey(docId)) {
        return 0;
    }
    
    // TF: ì •ê·œí™”ëœ ë‹¨ì–´ ë¹ˆë„
    int termCount = postings.get(docId);
    int docLength = documentLengths.get(docId);
    double tf = (double) termCount / docLength;
    
    // IDF: ì—­ë¬¸ì„œ ë¹ˆë„
    int totalDocs = documents.size();
    int docsWithTerm = postings.size();
    double idf = Math.log((double) totalDocs / docsWithTerm);
    
    return tf * idf;
}
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì—­ì¸ë±ìŠ¤ êµ¬í˜„
- [ ] í† í°í™” (ì†Œë¬¸ì, êµ¬ë‘ì  ì œê±°)
- [ ] ë¶ˆìš©ì–´ í•„í„°ë§
- [ ] ê¸°ë³¸ ê²€ìƒ‰ (AND/OR)
- [ ] TF-IDF ìŠ¤ì½”ì–´ë§
- [ ] ê²€ìƒ‰ ê²°ê³¼ ë­í‚¹
- [ ] êµ¬ë¬¸ ê²€ìƒ‰ (ì„ íƒ)
- [ ] ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰ (ì„ íƒ)

---

## ğŸ“š ì°¸ê³ 

- Apache Lucene
- Elasticsearch
- Apache Solr
- Information Retrieval êµì¬
