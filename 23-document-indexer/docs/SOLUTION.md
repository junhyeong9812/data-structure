# ë¬¸ì„œ ì¸ë±ì„œ í’€ì´ í•´ì„¤

## ğŸ“Œ í•µì‹¬ ì•„ì´ë””ì–´

ë¬¸ì„œ ì¸ë±ì„œëŠ” **ì—­ì¸ë±ìŠ¤**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ì—ì„œ ë¬¸ì„œë¡œì˜ 
ë§¤í•‘ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ O(1)ì— íŠ¹ì • ë‹¨ì–´ë¥¼ í¬í•¨í•˜ëŠ” 
ë¬¸ì„œ ëª©ë¡ì„ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ êµ¬ì„±ìš”ì†Œ**:
- ì—­ì¸ë±ìŠ¤ (ë‹¨ì–´ â†’ ë¬¸ì„œ ëª©ë¡)
- í† í°í™” (í…ìŠ¤íŠ¸ â†’ ë‹¨ì–´ ëª©ë¡)
- TF-IDF (ê²€ìƒ‰ ê´€ë ¨ì„± ì ìˆ˜)

---

## ğŸ”‘ í•µì‹¬ ê°œë…

### 1. ì—­ì¸ë±ìŠ¤ ìë£Œêµ¬ì¡°
```java
// ê¸°ë³¸ ì—­ì¸ë±ìŠ¤
Map<String, Set<String>> invertedIndex;
// term â†’ {docId1, docId2, ...}

// TF í¬í•¨ ì—­ì¸ë±ìŠ¤
Map<String, Map<String, Integer>> invertedIndexWithTf;
// term â†’ {docId â†’ termFrequency}

// ìœ„ì¹˜ í¬í•¨ ì—­ì¸ë±ìŠ¤ (êµ¬ë¬¸ ê²€ìƒ‰ìš©)
Map<String, Map<String, List<Integer>>> invertedIndexWithPositions;
// term â†’ {docId â†’ [position1, position2, ...]}
```

### 2. TF-IDF ê³µì‹
```
TF (Term Frequency):
  ë°©ë²• 1: ì›ì‹œ ë¹ˆë„
    tf(t,d) = f(t,d)  (ë‹¨ì–´ tê°€ ë¬¸ì„œ dì— ë‚˜íƒ€ë‚œ íšŸìˆ˜)
  
  ë°©ë²• 2: ì •ê·œí™”
    tf(t,d) = f(t,d) / (ë¬¸ì„œ dì˜ ì´ ë‹¨ì–´ ìˆ˜)
  
  ë°©ë²• 3: ë¡œê·¸ ìŠ¤ì¼€ì¼
    tf(t,d) = 1 + log(f(t,d))  (f > 0ì¼ ë•Œ)

IDF (Inverse Document Frequency):
  idf(t) = log(N / df(t))
  
  N = ì „ì²´ ë¬¸ì„œ ìˆ˜
  df(t) = ë‹¨ì–´ të¥¼ í¬í•¨í•˜ëŠ” ë¬¸ì„œ ìˆ˜

TF-IDF:
  tf-idf(t,d) = tf(t,d) Ã— idf(t)
```

### 3. Boolean ê²€ìƒ‰
```java
// AND ê²€ìƒ‰: ëª¨ë“  ë‹¨ì–´ í¬í•¨
Set<String> andSearch(List<String> terms) {
    if (terms.isEmpty()) return Set.of();
    
    Set<String> result = new HashSet<>(
        invertedIndex.getOrDefault(terms.get(0), Set.of())
    );
    
    for (int i = 1; i < terms.size(); i++) {
        result.retainAll(
            invertedIndex.getOrDefault(terms.get(i), Set.of())
        );
    }
    
    return result;
}

// OR ê²€ìƒ‰: í•˜ë‚˜ ì´ìƒ ë‹¨ì–´ í¬í•¨
Set<String> orSearch(List<String> terms) {
    Set<String> result = new HashSet<>();
    
    for (String term : terms) {
        result.addAll(
            invertedIndex.getOrDefault(term, Set.of())
        );
    }
    
    return result;
}
```

---

## ğŸ“ POP êµ¬í˜„ í•´ì„¤

### ì™„ì „í•œ êµ¬í˜„
```java
public class DocumentIndexer {
    private final Map<String, Map<String, Integer>> invertedIndex = new HashMap<>();
    private final Map<String, String> documents = new HashMap<>();
    private final Map<String, Integer> documentLengths = new HashMap<>();
    private final Set<String> stopWords;
    
    public DocumentIndexer() {
        this.stopWords = Set.of(
            "the", "a", "an", "is", "are", "was", "were",
            "in", "on", "at", "to", "for", "of", "and", "or"
        );
    }
    
    // ë¬¸ì„œ ì¶”ê°€
    public void addDocument(String docId, String content) {
        // ê¸°ì¡´ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ë¨¼ì € ì œê±°
        if (documents.containsKey(docId)) {
            removeDocument(docId);
        }
        
        documents.put(docId, content);
        
        List<String> tokens = tokenize(content);
        documentLengths.put(docId, tokens.size());
        
        // ë‹¨ì–´ë³„ ë¹ˆë„ ê³„ì‚°
        Map<String, Integer> termFreq = new HashMap<>();
        for (String token : tokens) {
            termFreq.merge(token, 1, Integer::sum);
        }
        
        // ì—­ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        for (Map.Entry<String, Integer> entry : termFreq.entrySet()) {
            invertedIndex.computeIfAbsent(entry.getKey(), k -> new HashMap<>())
                .put(docId, entry.getValue());
        }
    }
    
    // ë¬¸ì„œ ì œê±°
    public void removeDocument(String docId) {
        if (!documents.containsKey(docId)) return;
        
        String content = documents.remove(docId);
        documentLengths.remove(docId);
        
        List<String> tokens = tokenize(content);
        Set<String> uniqueTokens = new HashSet<>(tokens);
        
        for (String token : uniqueTokens) {
            Map<String, Integer> postings = invertedIndex.get(token);
            if (postings != null) {
                postings.remove(docId);
                if (postings.isEmpty()) {
                    invertedIndex.remove(token);
                }
            }
        }
    }
    
    // í† í°í™”
    private List<String> tokenize(String content) {
        return Arrays.stream(content.toLowerCase()
                .replaceAll("[^a-z0-9\\s]", "")
                .split("\\s+"))
            .filter(token -> !token.isEmpty())
            .filter(token -> token.length() > 1)
            .filter(token -> !stopWords.contains(token))
            .toList();
    }
    
    // ê¸°ë³¸ ê²€ìƒ‰ (AND)
    public List<String> search(String query) {
        return searchWithScore(query).stream()
            .map(SearchResult::docId)
            .toList();
    }
    
    // ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰
    public List<SearchResult> searchWithScore(String query) {
        List<String> queryTerms = tokenize(query);
        if (queryTerms.isEmpty()) {
            return List.of();
        }
        
        // AND ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ë¬¸ì„œ ì°¾ê¸°
        Set<String> candidates = andSearch(queryTerms);
        
        // TF-IDF ì ìˆ˜ ê³„ì‚°
        List<SearchResult> results = new ArrayList<>();
        for (String docId : candidates) {
            double score = 0;
            for (String term : queryTerms) {
                score += calculateTfIdf(term, docId);
            }
            results.add(new SearchResult(docId, score));
        }
        
        // ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results.sort((a, b) -> Double.compare(b.score(), a.score()));
        
        return results;
    }
    
    // OR ê²€ìƒ‰
    public List<SearchResult> searchOr(String query) {
        List<String> queryTerms = tokenize(query);
        if (queryTerms.isEmpty()) {
            return List.of();
        }
        
        Set<String> candidates = orSearch(queryTerms);
        
        List<SearchResult> results = new ArrayList<>();
        for (String docId : candidates) {
            double score = 0;
            for (String term : queryTerms) {
                score += calculateTfIdf(term, docId);
            }
            results.add(new SearchResult(docId, score));
        }
        
        results.sort((a, b) -> Double.compare(b.score(), a.score()));
        return results;
    }
    
    private Set<String> andSearch(List<String> terms) {
        if (terms.isEmpty()) return Set.of();
        
        Map<String, Integer> firstPostings = invertedIndex.get(terms.get(0));
        if (firstPostings == null) return Set.of();
        
        Set<String> result = new HashSet<>(firstPostings.keySet());
        
        for (int i = 1; i < terms.size(); i++) {
            Map<String, Integer> postings = invertedIndex.get(terms.get(i));
            if (postings == null) return Set.of();
            result.retainAll(postings.keySet());
        }
        
        return result;
    }
    
    private Set<String> orSearch(List<String> terms) {
        Set<String> result = new HashSet<>();
        for (String term : terms) {
            Map<String, Integer> postings = invertedIndex.get(term);
            if (postings != null) {
                result.addAll(postings.keySet());
            }
        }
        return result;
    }
    
    private double calculateTfIdf(String term, String docId) {
        Map<String, Integer> postings = invertedIndex.get(term);
        if (postings == null || !postings.containsKey(docId)) {
            return 0;
        }
        
        // TF
        int termCount = postings.get(docId);
        int docLength = documentLengths.get(docId);
        double tf = (double) termCount / docLength;
        
        // IDF
        int totalDocs = documents.size();
        int docsWithTerm = postings.size();
        double idf = Math.log((double) totalDocs / docsWithTerm);
        
        return tf * idf;
    }
    
    // í†µê³„
    public int getDocumentCount() {
        return documents.size();
    }
    
    public int getTermCount() {
        return invertedIndex.size();
    }
}
```

### SearchResult Record
```java
public record SearchResult(String docId, double score) {}
```

### êµ¬ë¬¸ ê²€ìƒ‰ (ìœ„ì¹˜ ê¸°ë°˜)
```java
public class PhraseSearchIndexer {
    // ìœ„ì¹˜ í¬í•¨ ì—­ì¸ë±ìŠ¤
    private final Map<String, Map<String, List<Integer>>> invertedIndex = new HashMap<>();
    
    public void addDocument(String docId, String content) {
        List<String> tokens = tokenize(content);
        
        for (int i = 0; i < tokens.size(); i++) {
            String token = tokens.get(i);
            invertedIndex.computeIfAbsent(token, k -> new HashMap<>())
                .computeIfAbsent(docId, k -> new ArrayList<>())
                .add(i);
        }
    }
    
    // êµ¬ë¬¸ ê²€ìƒ‰
    public List<String> phraseSearch(String phrase) {
        List<String> terms = tokenize(phrase);
        if (terms.isEmpty()) return List.of();
        
        // ì²« ë‹¨ì–´ë¥¼ í¬í•¨í•˜ëŠ” ë¬¸ì„œë“¤
        Map<String, List<Integer>> firstPostings = invertedIndex.get(terms.get(0));
        if (firstPostings == null) return List.of();
        
        List<String> results = new ArrayList<>();
        
        for (String docId : firstPostings.keySet()) {
            if (containsPhrase(docId, terms)) {
                results.add(docId);
            }
        }
        
        return results;
    }
    
    private boolean containsPhrase(String docId, List<String> terms) {
        List<Integer> positions = invertedIndex.get(terms.get(0)).get(docId);
        
        for (int startPos : positions) {
            boolean found = true;
            for (int i = 1; i < terms.size(); i++) {
                Map<String, List<Integer>> postings = invertedIndex.get(terms.get(i));
                if (postings == null || !postings.containsKey(docId)) {
                    found = false;
                    break;
                }
                
                List<Integer> termPositions = postings.get(docId);
                if (!termPositions.contains(startPos + i)) {
                    found = false;
                    break;
                }
            }
            
            if (found) return true;
        }
        
        return false;
    }
}
```

---

## â±ï¸ ë³µì¡ë„ ë¶„ì„

| ì—°ì‚° | ì‹œê°„ë³µì¡ë„ |
|------|-----------|
| addDocument | O(n) |
| removeDocument | O(n) |
| search (AND) | O(k Ã— m) |
| search (OR) | O(k Ã— m) |
| TF-IDF ê³„ì‚° | O(1) |

n = ë¬¸ì„œì˜ ë‹¨ì–´ ìˆ˜
k = ê²€ìƒ‰ì–´ ìˆ˜
m = ê²€ìƒ‰ì–´ë‹¹ í‰ê·  ë¬¸ì„œ ìˆ˜

---

## âŒ í”í•œ ì‹¤ìˆ˜

### 1. ë¹ˆ í† í° ì²˜ë¦¬
```java
// ì˜ëª»ë¨: ë¹ˆ í† í° í•„í„°ë§ ëˆ„ë½
String[] tokens = content.split("\\s+");
// "  hello  world  " â†’ ["", "hello", "", "world", ""]

// ì˜¬ë°”ë¦„: ë¹ˆ í† í° í•„í„°ë§
Arrays.stream(content.split("\\s+"))
    .filter(t -> !t.isEmpty())
    ...
```

### 2. ë¬¸ì„œ ì œê±° ì‹œ ì—­ì¸ë±ìŠ¤ ì •ë¦¬
```java
// ì˜ëª»ë¨: ì—­ì¸ë±ìŠ¤ì—ì„œ ì œê±° ì•ˆ í•¨
public void removeDocument(String docId) {
    documents.remove(docId);
    // ì—­ì¸ë±ìŠ¤ì— ì—¬ì „íˆ ì°¸ì¡° ë‚¨ì•„ìˆìŒ!
}

// ì˜¬ë°”ë¦„: ì—­ì¸ë±ìŠ¤ì—ì„œë„ ì œê±°
public void removeDocument(String docId) {
    String content = documents.remove(docId);
    for (String token : tokenize(content)) {
        Map<String, Integer> postings = invertedIndex.get(token);
        if (postings != null) {
            postings.remove(docId);
            if (postings.isEmpty()) {
                invertedIndex.remove(token);
            }
        }
    }
}
```

### 3. IDFì—ì„œ 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
```java
// ì˜ëª»ë¨: docsWithTermì´ 0ì¼ ë•Œ
double idf = Math.log(totalDocs / docsWithTerm);  // 0ìœ¼ë¡œ ë‚˜ëˆ”!

// ì˜¬ë°”ë¦„: ì²´í¬ ì¶”ê°€
if (docsWithTerm == 0) return 0;
double idf = Math.log((double) totalDocs / docsWithTerm);
```

---

## ğŸ”— ê´€ë ¨ ë¬¸ì œ

- ê²€ìƒ‰ ì—”ì§„ ì„¤ê³„
- ìë™ ì™„ì„± ì‹œìŠ¤í…œ
- ìœ ì‚¬ ë¬¸ì„œ ì°¾ê¸°
- ìŠ¤íŒ¸ í•„í„°
